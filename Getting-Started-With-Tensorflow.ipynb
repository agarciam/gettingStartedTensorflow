{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Core tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Computational Graph\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "node1 = tf.constant(3.0, dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "node2 = tf.constant(4.0) # also tf.float32 implicitly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const:0\", shape=(), dtype=float32) Tensor(\"Const_1:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(node1, node2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Notice that printing the nodes does not output the values 3.0 and 4.0 as you might expect. Instead, they are nodes that, when evaluated, would produce 3.0 and 4.0, respectively. To actually evaluate the nodes, we must run the computational graph within a session. A session encapsulates the control and state of the TensorFlow runtime.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.0, 4.0]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "print(sess.run([node1, node2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node3: Tensor(\"Add:0\", shape=(), dtype=float32)\n",
      "sess.run(node3): 7.0\n"
     ]
    }
   ],
   "source": [
    "node3 = tf.add(node1, node2)\n",
    "print(\"node3:\", node3)\n",
    "print(\"sess.run(node3):\", sess.run(node3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"A graph can be parameterized to accept external inputs, known as placeholders. A placeholder is a promise to provide a value later.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "adder_node = a + b  # + provides a shortcut for tf.add(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"The preceding three lines are a bit like a function or a <i> lambda </i> in which we define two input parameters (a and b) and then an operation on them. We can evaluate this graph with multiple inputs by using the feed_dict argument to the run method to feed concrete values to the placeholders:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.5\n",
      "[ 3.  7.]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(adder_node, {a: 3, b: 4.5}))\n",
    "print(sess.run(adder_node, {a: [1, 3], b: [2, 4]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <i> lambda function </i> \n",
    "from http://www.secnetix.de/olli/Python/lambda_functions.hawk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A normal function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print(f(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lamnda function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = lambda x: x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "print(g(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\" As you can see, f() and g() do exactly the same and can be used in the same ways. Note that the lambda definition does not include a \"return\" statement -- it always contains an expression which is returned. Also note that you can put a lambda definition anywhere a function is expected, and you don't have to assign it to a variable at all. \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_incrementor (n): return lambda x: x + n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = make_incrementor(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = make_incrementor(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "print(f(42))\n",
    "print(g(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "foo = [2, 18, 9, 22, 17, 24, 8, 12, 27]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <i> filter function </i> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<filter object at 0x7f4640eba1d0>\n"
     ]
    }
   ],
   "source": [
    "print(filter(lambda x: x % 3 == 0, foo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filter(lambda x: x % 3 == 0, foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<filter object at 0x7f4640eba9b0>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f =lambda x: x % 3 == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for %: 'list' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-bf54b656c11a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfoo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-6600d2d4dfbd>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for %: 'list' and 'int'"
     ]
    }
   ],
   "source": [
    "f(foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<filter at 0x7f464067ba58>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter(f, foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<filter at 0x7f464062e080>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter(f, [2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filterVowels(alphabet):\n",
    "    vowels = ['a', 'e', 'i', 'o', 'u']\n",
    "    \n",
    "    if (alphabet in vowels):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alphabets = ['a', 'b', 'c', 'd', 'e', 'i', 'j', 'o']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<filter object at 0x7f4640639518>\n"
     ]
    }
   ],
   "source": [
    "print(filter(filterVowels, alphabets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a  = filter(filterVowels, alphabets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "e\n",
      "i\n",
      "o\n"
     ]
    }
   ],
   "source": [
    "for i in a:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "9\n",
      "24\n",
      "12\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "for i in filter(lambda x: x % 3 == 0, foo):\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <i> .. continue lambda function </i> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "foo = [2, 18, 9, 22, 17, 24, 8, 12, 27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "9\n",
      "24\n",
      "12\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "for i in filter(lambda x: x % 3 == 0, foo):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "46\n",
      "28\n",
      "54\n",
      "44\n",
      "58\n",
      "26\n",
      "34\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "for i in map(lambda x: x * 2 + 10, foo):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reduce' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-bd6c961a14e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfoo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'reduce' is not defined"
     ]
    }
   ],
   "source": [
    "for i in reduce(lambda x, y: x + y, foo):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from: https://stackoverflow.com/a/13638960\n",
    "\"Removed reduce(). Use functools.reduce() if you really need it; however, 99 percent of the time an explicit for loop is more readable\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " nums = range(2, 50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(2, 8): \n",
    "    nums = filter(lambda x: x == i or x % i, nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<filter object at 0x7f46406395c0>\n"
     ]
    }
   ],
   "source": [
    "print(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "for i in nums:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ... continue with The computational graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"The preceding three lines are a bit like a function or a lambda in which we define two input parameters (a and b) and then an operation on them. We can evaluate this graph with multiple inputs by using the feed_dict argument to the run method to feed concrete values to the placeholders:\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tha part of the lambda function is almost clear, and just left the part of \"{a: 3, b: 4.5}\" which is a <i> dictionary </i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from https://docs.python.org/3/tutorial/datastructures.html\n",
    "\"It is best to think of a dictionary as an unordered set of key: value pairs, with the requirement that the keys are unique (within one dictionary). A pair of braces creates an empty dictionary: {}. Placing a comma-separated list of key:value pairs within the braces adds initial key:value pairs to the dictionary; this is also the way dictionaries are written on output.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tel = {'jack': 4098, 'sape': 4139}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tel['guido'] = 4127 #just like pandas add a column to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'guido': 4127, 'jack': 4098, 'sape': 4139}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4098"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tel['jack']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del tel['sape']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tel['irv'] = 4127"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'guido': 4127, 'irv': 4127, 'jack': 4098}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jack', 'guido', 'irv']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tel.keys()) #the same like in pandas list(DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['guido', 'irv', 'jack']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(tel.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'guido' in tel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'jack' not in tel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'guido': 4127, 'jack': 4098, 'sape': 4139}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict([('sape', 4139), ('guido', 4127), ('jack', 4098)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 4, 4: 16, 6: 36}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{x: x**2 for x in (2, 4, 6)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above can be read it as: defining the 'x' key as x^2, so giving the values 2, 4, 6 the dictionary get fixed as: {2: 4, 4: 16, 6: 36}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'guido': 4127, 'jack': 4098, 'sape': 4139}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(sape=4139, guido=4127, jack=4098)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knights = {'gallahad': 'the pure', 'robin': 'the brave'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gallahad the pure\n",
      "robin the brave\n"
     ]
    }
   ],
   "source": [
    "for k, v in knights.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tic\n",
      "1 tac\n",
      "2 toe\n"
     ]
    }
   ],
   "source": [
    "for i, v in enumerate(['tic', 'tac', 'toe']):\n",
    "    print(i, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ... continue with The computational graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.5\n",
      "[ 3.  7.]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "adder_node = a + b  # + provides a shortcut for tf.add(a, b)\n",
    "\n",
    "sess = tf.Session()\n",
    "print(sess.run(adder_node, {a: 3, b: 4.5}))\n",
    "print(sess.run(adder_node, {a: [1, 3], b: [2, 4]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 4, 4: 16, 6: 36}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "adder_node = a + b  # + provides a shortcut for tf.add(a, b)\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "dict1 = {b: 3, a: 4.5}\n",
    "dict2 = {b: [1, 2, 3], a:[1,2,3]}\n",
    "{x: x**2 for x in (2, 4, 6)}\n",
    "#print(sess.run(adder_node, dict1))\n",
    "#print(sess.run(adder_node, {a: [1, 3], b: [2, 4]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#how to create a [] list with lamnda function and give it to dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-85-e3c28bb6025a>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-85-e3c28bb6025a>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    lambda cu(x): return x**2\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "lambda cu(x): return x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "foo = [2, 18, 9, 22, 17, 24, 8, 12, 27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<map at 0x7f1df0faec88>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map(lambda x: x * 2 + 10, foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14, 46, 28, 54, 44, 58, 26, 34, 64]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda x: x * 2 + 10, foo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.5\n",
      "[ 5.  5.  5.  6.]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "adder_node = a + b  # + provides a shortcut for tf.add(a, b)\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "dict1 = {b: 3, a: 4.5}\n",
    "dict2 = {b: [1, 1, 1, 2], a:list(map(lambda x: x*2,  [2, 2, 2, 2]))}\n",
    "\n",
    "print(sess.run(adder_node, dict1))\n",
    "print(sess.run(adder_node, dict2))\n",
    "\n",
    "#yeah it works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.5\n"
     ]
    }
   ],
   "source": [
    "add_and_triple = adder_node * 3.\n",
    "print(sess.run(add_and_triple, {a: 3, b: 4.5}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"In machine learning we will typically want a model that can take arbitrary inputs, such as the one above. To make the model trainable, we need to be able to modify the graph to get new outputs with the same input. Variables allow us to add trainable parameters to a graph. They are constructed with a type and initial value\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable([.3], dtype=tf.float32)\n",
    "b = tf.Variable([-.3], dtype=tf.float32)\n",
    "x = tf.placeholder(tf.float32)\n",
    "linear_model = W * x + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Difference between tf.placeholder and tf.variable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from https://stackoverflow.com/a/39177244\n",
    "\"To sum up, if the values are from the samples(observations you already have) you safely make a placeholder to hold them, while if you need a parameter to be trained harness a Variable(simply put, set the Variables for the values you want to get using TF automatically).\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..getting started the computational graph:\n",
    "\"Constants are initialized when you call tf.constant, and their value can never change. By contrast, variables are not initialized when you call tf.Variable. To initialize all the variables in a TensorFlow program, you must explicitly call a special operation as follows:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.30000001  0.60000002  0.90000004]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(linear_model, {x: [1, 2, 3, 4]}))\n",
    "#note that the tf.placeholder 'x' is declared in the operacion\n",
    "#linear_model, something like a lamnda function...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.66\n"
     ]
    }
   ],
   "source": [
    "y = tf.placeholder(tf.float32)\n",
    "squared_deltas = tf.square(linear_model - y)\n",
    "loss = tf.reduce_sum(squared_deltas)\n",
    "print(sess.run(loss, {x: [1, 2, 3, 4], y: [0, -1, -2, -3]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "fixW = tf.assign(W, [-1.])\n",
    "fixb = tf.assign(b, [1.])\n",
    "sess.run([fixW, fixb])\n",
    "print(sess.run(loss, {x: [1, 2, 3, 4], y: [0, -1, -2, -3]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.30000001  0.60000002  0.90000004]\n",
      "23.66\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#declare some variables\n",
    "W = tf.Variable([.3], dtype=tf.float32) #\"matrix\" of weights\n",
    "b = tf.Variable([-.3], dtype=tf.float32) #bias\n",
    "x = tf.placeholder(tf.float32) #input data\n",
    "linear_model = W * x + b\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "print(sess.run(linear_model, {x: [1, 2, 3, 4]}))\n",
    "\n",
    "y = tf.placeholder(tf.float32)\n",
    "squared_deltas = tf.square(linear_model - y)\n",
    "loss = tf.reduce_sum(squared_deltas)\n",
    "print(sess.run(loss, {x: [1, 2, 3, 4], y: [0, -1, -2, -3]}))\n",
    "\n",
    "fixW = tf.assign(W, [-1.])\n",
    "fixb = tf.assign(b, [1.])\n",
    "sess.run([fixW, fixb])\n",
    "print(sess.run(loss, {x: [1, 2, 3, 4], y: [0, -1, -2, -3]}))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#declare some variables\n",
    "W = tf.Variable([.3], dtype=tf.float32) #\"matrix\" of weights\n",
    "b = tf.Variable([-.3], dtype=tf.float32) #bias\n",
    "x = tf.placeholder(tf.float32) #input data\n",
    "linear_model = W * x + b\n",
    "\n",
    "print(W)\n",
    "print(b)   \n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "print(sess.run(linear_model, {x: [1, 2, 3, 4]}))      #W, b, not initialized yet ERRROR\n",
    "\n",
    "#init = tf.global_variables_initializer()\n",
    "#sess.run(init)  # <==== remember\n",
    "# \"Constants are initialized when you call tf.constant,\n",
    "#and their value can never change. By contrast, variables \n",
    "#are not initialized when you call tf.Variable. To initialize \n",
    "#all the variables in a TensorFlow program, you must \n",
    "#explicitly call a special operation as follows:\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.30000001  0.60000002  0.90000004]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#declare some variables\n",
    "W = tf.Variable([.3], dtype=tf.float32) #\"matrix\" of weights\n",
    "b = tf.Variable([-.3], dtype=tf.float32) #bias\n",
    "x = tf.placeholder(tf.float32) #input data\n",
    "linear_model = W * x + b\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)  # <==== remember\n",
    "# \"Constants are initialized when you call tf.constant,\n",
    "#and their value can never change. By contrast, variables \n",
    "#are not initialized when you call tf.Variable. To initialize \n",
    "#all the variables in a TensorFlow program, you must \n",
    "#explicitly call a special operation as follows:\"\n",
    "\n",
    "#initialized !\n",
    "\n",
    "print(sess.run(linear_model, {x: [1, 2, 3, 4]})) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#all together till view loss 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.66\n",
      "Tensor(\"Assign:0\", shape=(1,), dtype=float32_ref)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#declare some variables\n",
    "W = tf.Variable([0.3], dtype=tf.float32) #\"matrix\" of weights\n",
    "b = tf.Variable([-0.3], dtype=tf.float32) #bias\n",
    "x = tf.placeholder(tf.float32) #input data\n",
    "linear_model = W * x + b\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)  # <==== remember\n",
    "# \"Constants are initialized when you call tf.constant,\n",
    "#and their value can never change. By contrast, variables \n",
    "#are not initialized when you call tf.Variable. To initialize \n",
    "#all the variables in a TensorFlow program, you must \n",
    "#explicitly call a special operation as follows:\"\n",
    "\n",
    "y = tf.placeholder(tf.float32)   #values to predict\n",
    "#squared_deltas = tf.square(linear_model - y) \n",
    "#loss = tf.reduce_sum(squared_deltas)\n",
    "loss = tf.reduce_sum(tf.square(linear_model - y)) #loss function\n",
    "print(sess.run(loss, {x: [1, 2, 3, 4], y: [0, -1, -2, -3]})) #model with \n",
    "#W = .3 and b = -0.3\n",
    "\n",
    "\n",
    "#assign new weights and bias (already know) to\n",
    "#get loss = 0\n",
    "\n",
    "fixW = tf.assign(W, [-1.])\n",
    "fixb = tf.assign(b, [1.])\n",
    "\n",
    "print(fixW)\n",
    "#sess.run([fixW, fixb])\n",
    "#print(sess.run(loss, {x: [1, 2, 3, 4], y: [0, -1, -2, -3]}))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.66\n",
      "Tensor(\"Assign_2:0\", shape=(1,), dtype=float32_ref)\n",
      "Tensor(\"Assign_3:0\", shape=(1,), dtype=float32_ref)\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#declare some variables\n",
    "W = tf.Variable([0.3], dtype=tf.float32) #\"matrix\" of weights\n",
    "b = tf.Variable([-0.3], dtype=tf.float32) #bias\n",
    "x = tf.placeholder(tf.float32) #input data\n",
    "linear_model = W * x + b\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)  # <==== remember\n",
    "# \"Constants are initialized when you call tf.constant,\n",
    "#and their value can never change. By contrast, variables \n",
    "#are not initialized when you call tf.Variable. To initialize \n",
    "#all the variables in a TensorFlow program, you must \n",
    "#explicitly call a special operation as follows:\"\n",
    "\n",
    "y = tf.placeholder(tf.float32)   #values to predict\n",
    "#squared_deltas = tf.square(linear_model - y) \n",
    "#loss = tf.reduce_sum(squared_deltas)\n",
    "loss = tf.reduce_sum(tf.square(linear_model - y)) #loss function\n",
    "print(sess.run(loss, {x: [1, 2, 3, 4], y: [0, -1, -2, -3]})) #model with \n",
    "#W = .3 and b = -0.3\n",
    "\n",
    "\n",
    "#assign new weights and bias (already know) to\n",
    "#get loss = 0\n",
    "\n",
    "fixW = tf.assign(W, [-1.])\n",
    "fixb = tf.assign(b, [1.])\n",
    "print(fixW)\n",
    "print(fixb)\n",
    "sess.run([fixW, fixb]) #its like compile model? need it to validate the assign?\n",
    "print(sess.run(loss, {x: [1, 2, 3, 4], y: [0, -1, -2, -3]}))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.train API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"A complete discussion of machine learning is out of the scope of this tutorial. However, TensorFlow provides optimizers that slowly change each variable in order to minimize the loss function. The simplest optimizer is gradient descent. It modifies each variable according to the magnitude of the derivative of loss with respect to that variable. In general, computing symbolic derivatives manually is tedious and error-prone. Consequently, TensorFlow can automatically produce derivatives given only a description of the model using the function tf.gradients. For simplicity, optimizers typically do this for you. For example,\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "[array([-0.52916396], dtype=float32), array([-0.38427448], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "sess.run(init) # reset values to incorrect defaults.\n",
    "for i in range(10):\n",
    "    print(sess.run(train, {x: [1, 2, 3, 4], y: [0, -1, -2, -3]}))\n",
    "\n",
    "print(sess.run([W, b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-0.99999911], dtype=float32), array([ 0.99999744], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "sess.run(init) # reset values to incorrect defaults.\n",
    "for i in range(10000):\n",
    "    sess.run(train, {x: [1, 2, 3, 4], y: [0, -1, -2, -3]})\n",
    "\n",
    "print(sess.run([W, b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-0.21999997], dtype=float32), array([-0.456], dtype=float32)]\n",
      "[array([-0.39679998], dtype=float32), array([-0.49552], dtype=float32)]\n",
      "[array([-0.45961601], dtype=float32), array([-0.4965184], dtype=float32)]\n",
      "[array([-0.48454273], dtype=float32), array([-0.48487374], dtype=float32)]\n",
      "[array([-0.49684232], dtype=float32), array([-0.46917531], dtype=float32)]\n",
      "[array([-0.50490189], dtype=float32), array([-0.45227283], dtype=float32)]\n",
      "[array([-0.5115062], dtype=float32), array([-0.43511063], dtype=float32)]\n",
      "[array([-0.51758033], dtype=float32), array([-0.41800055], dtype=float32)]\n",
      "[array([-0.52343202], dtype=float32), array([-0.40104443], dtype=float32)]\n",
      "[array([-0.52916396], dtype=float32), array([-0.38427448], dtype=float32)]\n",
      "FINAL W B [array([-0.52916396], dtype=float32), array([-0.38427448], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "sess.run(init) # reset values to incorrect defaults.\n",
    "for i in range(10):\n",
    "    sess.run(train, {x: [1, 2, 3, 4], y: [0, -1, -2, -3]})\n",
    "    print(sess.run([W, b]))\n",
    "    \n",
    "print(\"FINAL W B {}\".format(sess.run([W, b])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: [-0.9999969] b: [ 0.99999082] loss: 5.69997e-11\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Model parameters\n",
    "W = tf.Variable([.3], dtype=tf.float32)\n",
    "b = tf.Variable([-.3], dtype=tf.float32)\n",
    "# Model input and output\n",
    "x = tf.placeholder(tf.float32)\n",
    "linear_model = W * x + b\n",
    "y = tf.placeholder(tf.float32)\n",
    "\n",
    "# loss\n",
    "loss = tf.reduce_sum(tf.square(linear_model - y)) # sum of the squares\n",
    "# optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "# training data\n",
    "x_train = [1, 2, 3, 4]\n",
    "y_train = [0, -1, -2, -3]\n",
    "# training loop\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init) # reset values to wrong\n",
    "for i in range(1000):\n",
    "    sess.run(train, {x: x_train, y: y_train})\n",
    "\n",
    "# evaluate training accuracy\n",
    "curr_W, curr_b, curr_loss = sess.run([W, b, loss], {x: x_train, y: y_train})\n",
    "print(\"W: %s b: %s loss: %s\"%(curr_W, curr_b, curr_loss))\n",
    "\n",
    "#OK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#https://www.tensorflow.org/get_started/get_started#tftrain_api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.estimator is a high-level TensorFlow library that simplifies the mechanics of machine learning, including the following:\n",
    "\n",
    "running training loops <br>\n",
    "running evaluation loops <br>\n",
    "managing data sets <br>\n",
    "tf.estimator defines many common models.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'feature_column'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-eedbcdd50989>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Declare list of features. We only have one numeric feature. There are many\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# other types of columns that are more complicated and useful.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mfeature_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_column\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumeric_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# An estimator is the front end to invoke training (fitting) and evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'feature_column'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# NumPy is often used to load, manipulate and preprocess data.\n",
    "import numpy as np\n",
    "\n",
    "# Declare list of features. We only have one numeric feature. There are many\n",
    "# other types of columns that are more complicated and useful.\n",
    "feature_columns = [tf.feature_column.numeric_column(\"x\", shape=[1])]\n",
    "\n",
    "# An estimator is the front end to invoke training (fitting) and evaluation\n",
    "# (inference). There are many predefined types like linear regression,\n",
    "# linear classification, and many neural network classifiers and regressors.\n",
    "# The following code provides an estimator that does linear regression.\n",
    "estimator = tf.estimator.LinearRegressor(feature_columns=feature_columns)\n",
    "\n",
    "# TensorFlow provides many helper methods to read and set up data sets.\n",
    "# Here we use two data sets: one for training and one for evaluation\n",
    "# We have to tell the function how many batches\n",
    "# of data (num_epochs) we want and how big each batch should be.\n",
    "x_train = np.array([1., 2., 3., 4.])\n",
    "y_train = np.array([0., -1., -2., -3.])\n",
    "x_eval = np.array([2., 5., 8., 1.])\n",
    "y_eval = np.array([-1.01, -4.1, -7, 0.])\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\\\n",
    "    {\"x\": x_train}, y_train, batch_size=4, num_epochs=None, shuffle=True)\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\\\n",
    "    {\"x\": x_train}, y_train, batch_size=4, num_epochs=1000, shuffle=False)\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\\\n",
    "    {\"x\": x_eval}, y_eval, batch_size=4, num_epochs=1000, shuffle=False)\n",
    "\n",
    "# We can invoke 1000 training steps by invoking the  method and passing the\n",
    "# training data set.\n",
    "estimator.train(input_fn=input_fn, steps=1000)\n",
    "\n",
    "# Here we evaluate how well our model did.\n",
    "train_metrics = estimator.evaluate(input_fn=train_input_fn)\n",
    "eval_metrics = estimator.evaluate(input_fn=eval_input_fn)\n",
    "print(\"train metrics: %r\"% train_metrics)\n",
    "print(\"eval metrics: %r\"% eval_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# NumPy is often used to load, manipulate and preprocess data.\n",
    "import numpy as np\n",
    "\n",
    "# Declare list of features. We only have one numeric feature. There are many\n",
    "# other types of columns that are more complicated and useful.\n",
    "feature_columns = [tf.feature_column.numeric_column(\"x\", shape=[1])]\n",
    "\n",
    "#steps to correcto errror \"# An estimator is the front end to invoke training (fitting) and evaluation\"\n",
    "#from anaconda enviroment\n",
    "\n",
    "#1. source activate tensorflow\n",
    "#2. (tensorflow) user$: pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-1.3.0-cp36-cp36m-linux_x86_64.whl\n",
    "# or last version in url direction https://www.tensorflow.org/install/install_linux#the_url_of_the_tensorflow_python_package\n",
    "#3. (tensorflow) user$: source deactivate tensorflow\n",
    "#4. user$: source activate tensorflow\n",
    "#5. (tensorflow) user$: conda install jupyter\n",
    "#6. (tensorflow) user$: source deactivate tensorflow\n",
    "#7. user$: source activate tensorflow\n",
    "#8. (tensorflow) user$: conda update jupyter\n",
    "#9  (tensorflow) user$: source deactivate tensorflow\n",
    "#10. user$: source activate tensorflow\n",
    "#11. (tensorflow) user$:jupyter notebook\n",
    "\n",
    "#12 DONE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#what does feature_column.numeric???\n",
    "\n",
    "#..from https://www.tensorflow.org/get_started/get_started#tftrain_api\n",
    "\n",
    "# Declare list of features. We only have one numeric feature. There are many\n",
    "# other types of columns that are more complicated and useful.\n",
    "\n",
    "#from github https://github.com/tensorflow/tensorflow/blob/r1.3/tensorflow/python/feature_column/feature_column.py\n",
    "#\"\"\"This API defines FeatureColumn abstraction.\n",
    "#FeatureColumns provide a high level abstraction for ingesting and representing\n",
    "#features. FeatureColumns are also the primary way of encoding features for\n",
    "#canned ${tf.estimator.Estimator}s.\n",
    "#When using FeatureColumns with `Estimators`, the type of feature column you\n",
    "#should choose depends on (1) the feature type and (2) the model type.\n",
    "#1. Feature type:\n",
    "#  * Continuous features can be represented by `numeric_column`.\n",
    "#  * Categorical features can be represented by any `categorical_column_with_*`\n",
    "#  column:\n",
    "#    - `categorical_column_with_vocabulary_list`\n",
    "#    - `categorical_column_with_vocabulary_file`\n",
    "#    - `categorical_column_with_hash_bucket`\n",
    "#    - `categorical_column_with_identity`\n",
    "#    - `weighted_categorical_column`\n",
    "#2. Model type:\n",
    "#  * Deep neural network models (`DNNClassifier`, `DNNRegressor`).\n",
    "#    Continuous features can be directly fed into deep neural network models.\n",
    "#      age_column = numeric_column(\"age\")\n",
    "#    To feed sparse features into DNN models, wrap the column with\n",
    "#    `embedding_column` or `indicator_column`. `indicator_column` is recommended\n",
    "#    for features with only a few possible values. For features with many\n",
    "#    possible values, to reduce the size of your model, `embedding_column` is\n",
    "#    recommended.\n",
    "#      embedded_dept_column = embedding_column(\n",
    "#          categorical_column_with_vocabulary_list(\n",
    "#              \"department\", [\"math\", \"philosphy\", ...]), dimension=10)\n",
    "#  * Wide (aka linear) models (`LinearClassifier`, `LinearRegressor`).\n",
    "#    Sparse features can be fed directly into linear models. They behave like an\n",
    "#    indicator column but with an efficient implementation.\n",
    "#      dept_column = categorical_column_with_vocabulary_list(\"department\",\n",
    "#          [\"math\", \"philosophy\", \"english\"])\n",
    "#    It is recommended that continuous features be bucketized before being\n",
    "#    fed into linear models.\n",
    "#      bucketized_age_column = bucketized_column(\n",
    "#          source_column=age_column,\n",
    "#          boundaries=[18, 25, 30, 35, 40, 45, 50, 55, 60, 65])\n",
    "#    Sparse features can be crossed (also known as conjuncted or combined) in\n",
    "#    order to form non-linearities, and then fed into linear models.\n",
    "#      cross_dept_age_column = crossed_column(\n",
    "#          columns=[\"department\", bucketized_age_column],\n",
    "#          hash_bucket_size=1000)\n",
    "#Example of building canned `Estimator`s using FeatureColumns:\n",
    "#  ```python\n",
    "#  # Define features and transformations\n",
    "#  deep_feature_columns = [age_column, embedded_dept_column]\n",
    "#  wide_feature_columns = [dept_column, bucketized_age_column,\n",
    "#      cross_dept_age_column]\n",
    "#  # Build deep model\n",
    "#  estimator = DNNClassifier(\n",
    "#      feature_columns=deep_feature_columns,\n",
    "#      hidden_units=[500, 250, 50])\n",
    "#  estimator.train(...)\n",
    "#  # Or build a wide model\n",
    "#  estimator = LinearClassifier(\n",
    "#      feature_columns=wide_feature_columns)\n",
    "#  estimator.train(...)\n",
    "#  # Or build a wide and deep model!\n",
    "#  estimator = DNNLinearCombinedClassifier(\n",
    "#      linear_feature_columns=wide_feature_columns,\n",
    "#      dnn_feature_columns=deep_feature_columns,\n",
    "#      dnn_hidden_units=[500, 250, 50])\n",
    "#  estimator.train(...)\n",
    "#  ```\n",
    "#FeatureColumns can also be transformed into a generic input layer for\n",
    "#custom models using `input_layer`.\n",
    "#Example of building model using FeatureColumns, this can be used in a\n",
    "#`model_fn` which is given to the {tf.estimator.Estimator}:\n",
    "#  ```python\n",
    "#  # Building model via layers\n",
    "#  deep_feature_columns = [age_column, embedded_dept_column]\n",
    "#  columns_to_tensor = parse_feature_columns_from_examples(\n",
    "#      serialized=my_data,\n",
    "#      feature_columns=deep_feature_columns)\n",
    "#  first_layer = input_layer(\n",
    "#      features=columns_to_tensor,\n",
    "#      feature_columns=deep_feature_columns)\n",
    "#  second_layer = fully_connected(first_layer, ...)\n",
    "#  ```\n",
    "#NOTE: Functions prefixed with \"_\" indicate experimental or private parts of\n",
    "#the API subject to change, and should not be relied upon!\n",
    "\n",
    "#\"\"\"\n",
    "\n",
    "# not fully understood  ... pending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpta1dse98\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpta1dse98', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmpta1dse98/model.ckpt.\n",
      "INFO:tensorflow:loss = 11.0, step = 1\n",
      "INFO:tensorflow:global_step/sec: 789.705\n",
      "INFO:tensorflow:loss = 0.134901, step = 101 (0.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 882.666\n",
      "INFO:tensorflow:loss = 0.0378195, step = 201 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 868.086\n",
      "INFO:tensorflow:loss = 0.0206988, step = 301 (0.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 836.437\n",
      "INFO:tensorflow:loss = 0.00289665, step = 401 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 849.177\n",
      "INFO:tensorflow:loss = 0.000148321, step = 501 (0.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 834.609\n",
      "INFO:tensorflow:loss = 0.000131132, step = 601 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 903.493\n",
      "INFO:tensorflow:loss = 2.56187e-05, step = 701 (0.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 910.91\n",
      "INFO:tensorflow:loss = 1.99793e-06, step = 801 (0.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 896.796\n",
      "INFO:tensorflow:loss = 7.4026e-07, step = 901 (0.112 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmpta1dse98/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2.19156e-07.\n",
      "INFO:tensorflow:Starting evaluation at 2017-09-19-04:43:07\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpta1dse98/model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-09-19-04:43:08\n",
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 3.68103e-08, global_step = 1000, loss = 1.47241e-07\n",
      "INFO:tensorflow:Starting evaluation at 2017-09-19-04:43:08\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpta1dse98/model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-09-19-04:43:09\n",
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 0.00254313, global_step = 1000, loss = 0.0101725\n",
      "train metrics: {'average_loss': 3.6810274e-08, 'loss': 1.472411e-07, 'global_step': 1000}\n",
      "eval metrics: {'average_loss': 0.0025431348, 'loss': 0.010172539, 'global_step': 1000}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# NumPy is often used to load, manipulate and preprocess data.\n",
    "import numpy as np\n",
    "\n",
    "# Declare list of features. We only have one numeric feature. There are many\n",
    "# other types of columns that are more complicated and useful.\n",
    "feature_columns = [tf.feature_column.numeric_column(\"x\", shape=[1])]\n",
    "\n",
    "# An estimator is the front end to invoke training (fitting) and evaluation\n",
    "# (inference). There are many predefined types like linear regression,\n",
    "# linear classification, and many neural network classifiers and regressors.\n",
    "# The following code provides an estimator that does linear regression.\n",
    "estimator = tf.estimator.LinearRegressor(feature_columns=feature_columns)\n",
    "\n",
    "# TensorFlow provides many helper methods to read and set up data sets.\n",
    "# Here we use two data sets: one for training and one for evaluation\n",
    "# We have to tell the function how many batches\n",
    "# of data (num_epochs) we want and how big each batch should be.\n",
    "x_train = np.array([1., 2., 3., 4.])\n",
    "y_train = np.array([0., -1., -2., -3.])\n",
    "x_eval = np.array([2., 5., 8., 1.])\n",
    "y_eval = np.array([-1.01, -4.1, -7, 0.])\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_train}, y_train, batch_size=4, num_epochs=None, shuffle=True)\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_train}, y_train, batch_size=4, num_epochs=1000, shuffle=False)\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_eval}, y_eval, batch_size=4, num_epochs=1000, shuffle=False)\n",
    "\n",
    "# We can invoke 1000 training steps by invoking the  method and passing the\n",
    "# training data set.\n",
    "estimator.train(input_fn=input_fn, steps=1000)\n",
    "\n",
    "# Here we evaluate how well our model did.\n",
    "train_metrics = estimator.evaluate(input_fn=train_input_fn)\n",
    "eval_metrics = estimator.evaluate(input_fn=eval_input_fn)\n",
    "print(\"train metrics: %r\"% train_metrics)\n",
    "print(\"eval metrics: %r\"% eval_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpy7i6ibre\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpy7i6ibre', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmpy7i6ibre/model.ckpt.\n",
      "INFO:tensorflow:loss = 250.635, step = 1\n",
      "INFO:tensorflow:global_step/sec: 422.934\n",
      "INFO:tensorflow:loss = 250.925, step = 101 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.389\n",
      "INFO:tensorflow:loss = 244.181, step = 201 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 414.543\n",
      "INFO:tensorflow:loss = 257.298, step = 301 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 418.873\n",
      "INFO:tensorflow:loss = 251.935, step = 401 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 464.512\n",
      "INFO:tensorflow:loss = 250.884, step = 501 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.381\n",
      "INFO:tensorflow:loss = 251.112, step = 601 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 411.986\n",
      "INFO:tensorflow:loss = 252.887, step = 701 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 421.47\n",
      "INFO:tensorflow:loss = 230.752, step = 801 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.887\n",
      "INFO:tensorflow:loss = 242.536, step = 901 (0.236 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmpy7i6ibre/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 248.369.\n",
      "INFO:tensorflow:Starting evaluation at 2017-09-19-04:43:32\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpy7i6ibre/model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-09-19-04:43:33\n",
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 0.498406, global_step = 1000, loss = 249.203\n",
      "INFO:tensorflow:Starting evaluation at 2017-09-19-04:43:33\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpy7i6ibre/model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-09-19-04:43:34\n",
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 0.527504, global_step = 1000, loss = 263.752\n",
      "train metrics: {'average_loss': 0.4984065, 'loss': 249.20325, 'global_step': 1000}\n",
      "eval metrics: {'average_loss': 0.52750361, 'loss': 263.7518, 'global_step': 1000}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# NumPy is often used to load, manipulate and preprocess data.\n",
    "import numpy as np\n",
    "\n",
    "feature_columns = [tf.feature_column.numeric_column(\"x\", shape=[1])]\n",
    "\n",
    "estimator = tf.estimator.LinearRegressor(feature_columns=feature_columns)\n",
    "\n",
    "#x_train = np.array([1., 2., 3., 4.])\n",
    "#y_train = np.array([0., -1., -2., -3.])\n",
    "#x_eval = np.array([2., 5., 8., 1.])\n",
    "#y_eval = np.array([-1.01, -4.1, -7, 0.])\n",
    "\n",
    "X = np.arange(0, 100, 0.2)\n",
    "Y = np.sin(X)\n",
    "L = np.array(X.shape[0]/2).astype(int)\n",
    "\n",
    "x_train = X[0:L]\n",
    "y_train = Y[0:L]\n",
    "x_eval = X[L:]\n",
    "y_eval = Y[L:]\n",
    "\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_train}, y_train, batch_size=500, num_epochs=None, shuffle=True)\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_train}, y_train, batch_size=500, num_epochs=1000, shuffle=False)\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_eval}, y_eval, batch_size=500, num_epochs=1000, shuffle=False)\n",
    "\n",
    "estimator.train(input_fn=input_fn, steps=1000)\n",
    "\n",
    "train_metrics = estimator.evaluate(input_fn=train_input_fn)\n",
    "eval_metrics = estimator.evaluate(input_fn=eval_input_fn)\n",
    "print(\"train metrics: %r\"% train_metrics)\n",
    "print(\"eval metrics: %r\"% eval_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.arange(0, 100, 0.2)\n",
    "Y = np.sin(X)\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A custom model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"tf.estimator does not lock you into its predefined models. Suppose we wanted to create a custom model that is not built into TensorFlow. We can still retain the high level abstraction of data set, feeding, training, etc. of tf.estimator. For illustration, we will show how to implement our own equivalent model to LinearRegressor using our knowledge of the lower level TensorFlow API.\n",
    "\n",
    "To define a custom model that works with tf.estimator, we need to use tf.estimator.Estimator. tf.estimator.LinearRegressor is actually a sub-class of tf.estimator.Estimator. Instead of sub-classing Estimator, we simply provide Estimator a function model_fn that tells tf.estimator how it can evaluate predictions, training steps, and loss. The code is as follows:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpfp0w4yul\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpfp0w4yul', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmpfp0w4yul/model.ckpt.\n",
      "INFO:tensorflow:loss = 7.47341230794, step = 1\n",
      "INFO:tensorflow:global_step/sec: 989.937\n",
      "INFO:tensorflow:loss = 0.0597347157923, step = 101 (0.102 sec)\n",
      "INFO:tensorflow:global_step/sec: 1282.92\n",
      "INFO:tensorflow:loss = 0.00294375348015, step = 201 (0.078 sec)\n",
      "INFO:tensorflow:global_step/sec: 1131.93\n",
      "INFO:tensorflow:loss = 0.000568280667108, step = 301 (0.088 sec)\n",
      "INFO:tensorflow:global_step/sec: 1160.81\n",
      "INFO:tensorflow:loss = 4.85880375876e-05, step = 401 (0.086 sec)\n",
      "INFO:tensorflow:global_step/sec: 1248.93\n",
      "INFO:tensorflow:loss = 3.01538313479e-06, step = 501 (0.080 sec)\n",
      "INFO:tensorflow:global_step/sec: 1183.66\n",
      "INFO:tensorflow:loss = 1.99576697419e-07, step = 601 (0.085 sec)\n",
      "INFO:tensorflow:global_step/sec: 1267.9\n",
      "INFO:tensorflow:loss = 1.11340699059e-08, step = 701 (0.079 sec)\n",
      "INFO:tensorflow:global_step/sec: 1195.13\n",
      "INFO:tensorflow:loss = 7.16144204194e-10, step = 801 (0.084 sec)\n",
      "INFO:tensorflow:global_step/sec: 1018.12\n",
      "INFO:tensorflow:loss = 1.37731336392e-10, step = 901 (0.098 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmpfp0w4yul/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6.73010642755e-12.\n",
      "INFO:tensorflow:Starting evaluation at 2017-09-19-04:31:30\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpfp0w4yul/model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-09-19-04:31:31\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 1.09317e-11\n",
      "INFO:tensorflow:Starting evaluation at 2017-09-19-04:31:31\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpfp0w4yul/model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-09-19-04:31:31\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 0.0101004\n",
      "train metrics: {'loss': 1.0931696e-11, 'global_step': 1000}\n",
      "eval metrics: {'loss': 0.010100389, 'global_step': 1000}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Declare list of features, we only have one real-valued feature\n",
    "def model_fn(features, labels, mode):\n",
    "  # Build a linear model and predict values\n",
    "  W = tf.get_variable(\"W\", [1], dtype=tf.float64)\n",
    "  b = tf.get_variable(\"b\", [1], dtype=tf.float64)\n",
    "  y = W * features['x'] + b\n",
    "  # Loss sub-graph\n",
    "  loss = tf.reduce_sum(tf.square(y - labels))\n",
    "  # Training sub-graph\n",
    "  global_step = tf.train.get_global_step()\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "  train = tf.group(optimizer.minimize(loss),\n",
    "                   tf.assign_add(global_step, 1))\n",
    "  # EstimatorSpec connects subgraphs we built to the\n",
    "  # appropriate functionality.\n",
    "  return tf.estimator.EstimatorSpec(\n",
    "      mode=mode,\n",
    "      predictions=y,\n",
    "      loss=loss,\n",
    "      train_op=train)\n",
    "\n",
    "estimator = tf.estimator.Estimator(model_fn=model_fn)\n",
    "# define our data sets\n",
    "x_train = np.array([1., 2., 3., 4.])\n",
    "y_train = np.array([0., -1., -2., -3.])\n",
    "x_eval = np.array([2., 5., 8., 1.])\n",
    "y_eval = np.array([-1.01, -4.1, -7, 0.])\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_train}, y_train, batch_size=4, num_epochs=None, shuffle=True)\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_train}, y_train, batch_size=4, num_epochs=1000, shuffle=False)\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_eval}, y_eval, batch_size=4, num_epochs=1000, shuffle=False)\n",
    "\n",
    "# train\n",
    "estimator.train(input_fn=input_fn, steps=1000)\n",
    "# Here we evaluate how well our model did.\n",
    "train_metrics = estimator.evaluate(input_fn=train_input_fn)\n",
    "eval_metrics = estimator.evaluate(input_fn=eval_input_fn)\n",
    "print(\"train metrics: %r\"% train_metrics)\n",
    "print(\"eval metrics: %r\"% eval_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#trying to get work a sin function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "\n",
    "# Declare list of features, we only have one real-valued feature\n",
    "def model_fn(features, labels, mode):\n",
    "    # Build a linear model and predict values\n",
    "    W = tf.get_variable(\"W\", [1], dtype=tf.float64)\n",
    "    b = tf.get_variable(\"b\", [1], dtype=tf.float64)\n",
    "    y = W * features['x'] + b\n",
    "    # Loss sub-graph\n",
    "    loss = tf.reduce_sum(tf.square(y - labels))\n",
    "    # Training sub-graph\n",
    "    global_step = tf.train.get_global_step()\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    train = tf.group(optimizer.minimize(loss),\n",
    "                   tf.assign_add(global_step, 1))\n",
    "    # EstimatorSpec connects subgraphs we built to the\n",
    "    # appropriate functionality.\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "      mode=mode,\n",
    "      predictions=y,\n",
    "      loss=loss,\n",
    "      train_op=train)\n",
    "\n",
    "estimator = tf.estimator.Estimator(model_fn=model_fn)\n",
    "# define our data sets\n",
    "X = np.arange(0, 1000, .2)\n",
    "#Y = np.sin(X)\n",
    "Y = X \n",
    "\n",
    "x_train, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp2w1lfh9q\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp2w1lfh9q', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmp2w1lfh9q/model.ckpt.\n",
      "INFO:tensorflow:loss = 5.22943652038, step = 1\n",
      "INFO:tensorflow:global_step/sec: 930.758\n",
      "INFO:tensorflow:loss = 1.88051651181, step = 101 (0.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 916.848\n",
      "INFO:tensorflow:loss = 0.508640905373, step = 201 (0.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 959.172\n",
      "INFO:tensorflow:loss = 0.0989183679018, step = 301 (0.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 977.634\n",
      "INFO:tensorflow:loss = 0.0134541018123, step = 401 (0.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 877.714\n",
      "INFO:tensorflow:loss = 0.00126678688729, step = 501 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 929.694\n",
      "INFO:tensorflow:loss = 8.199077538e-05, step = 601 (0.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 987.792\n",
      "INFO:tensorflow:loss = 3.60467542363e-06, step = 701 (0.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 878.883\n",
      "INFO:tensorflow:loss = 1.05631584858e-07, step = 801 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 902.325\n",
      "INFO:tensorflow:loss = 2.00901055425e-09, step = 901 (0.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 907.108\n",
      "INFO:tensorflow:loss = 2.39300346899e-11, step = 1001 (0.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 870.002\n",
      "INFO:tensorflow:loss = 1.7026433596e-13, step = 1101 (0.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 887.496\n",
      "INFO:tensorflow:loss = 6.78849701456e-16, step = 1201 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 843.227\n",
      "INFO:tensorflow:loss = 1.38648950346e-18, step = 1301 (0.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 793.587\n",
      "INFO:tensorflow:loss = 1.25600429347e-21, step = 1401 (0.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 765.464\n",
      "INFO:tensorflow:loss = 8.04518216468e-25, step = 1501 (0.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 758.995\n",
      "INFO:tensorflow:loss = 2.53697667119e-27, step = 1601 (0.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 879.385\n",
      "INFO:tensorflow:loss = 3.02922587605e-28, step = 1701 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 903.404\n",
      "INFO:tensorflow:loss = 1.35684075698e-28, step = 1801 (0.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 781.211\n",
      "INFO:tensorflow:loss = 1.89326617253e-28, step = 1901 (0.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 836.43\n",
      "INFO:tensorflow:loss = 5.04870979341e-29, step = 2001 (0.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 879.796\n",
      "INFO:tensorflow:loss = 3.42291677156e-29, step = 2101 (0.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 890.178\n",
      "INFO:tensorflow:loss = 1.26217744835e-29, step = 2201 (0.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 891.603\n",
      "INFO:tensorflow:loss = 2.28769662514e-29, step = 2301 (0.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 884.402\n",
      "INFO:tensorflow:loss = 2.60817136789e-29, step = 2401 (0.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 941.231\n",
      "INFO:tensorflow:loss = 3.15544362088e-30, step = 2501 (0.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 779.602\n",
      "INFO:tensorflow:loss = 0.0, step = 2601 (0.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 792.736\n",
      "INFO:tensorflow:loss = 9.46633086265e-30, step = 2701 (0.126 sec)\n",
      "INFO:tensorflow:global_step/sec: 824.942\n",
      "INFO:tensorflow:loss = 6.31088724177e-30, step = 2801 (0.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 804.14\n",
      "INFO:tensorflow:loss = 7.09974814699e-30, step = 2901 (0.124 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3000 into /tmp/tmp2w1lfh9q/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 6.72996959767e-30.\n",
      "INFO:tensorflow:Starting evaluation at 2017-09-19-05:24:25\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp2w1lfh9q/model.ckpt-3000\n",
      "INFO:tensorflow:Finished evaluation at 2017-09-19-05:26:36\n",
      "INFO:tensorflow:Saving dict for global step 3000: global_step = 3000, loss = 3.09516e-30\n",
      "INFO:tensorflow:Starting evaluation at 2017-09-19-05:26:36\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp2w1lfh9q/model.ckpt-3000\n",
      "INFO:tensorflow:Finished evaluation at 2017-09-19-05:27:26\n",
      "INFO:tensorflow:Saving dict for global step 3000: global_step = 3000, loss = 3.69581e-30\n",
      "train metrics: {'loss': 3.0951611e-30, 'global_step': 3000}\n",
      "eval metrics: {'loss': 3.6958133e-30, 'global_step': 3000}\n"
     ]
    }
   ],
   "source": [
    "#trying to get work a sin function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "\n",
    "# Declare list of features, we only have one real-valued feature\n",
    "def model_fn(features, labels, mode):\n",
    "    # Build a linear model and predict values\n",
    "    #W = tf.get_variable(\"W\", [1], dtype=tf.float64)\n",
    "    b = tf.get_variable(\"b\", [1], dtype=tf.float64)\n",
    "    #y = W * features['x'] + b\n",
    "    y = features['x'] + b\n",
    "    # Loss sub-graph\n",
    "    loss = tf.reduce_sum(tf.square(y - labels))\n",
    "    # Training sub-graph\n",
    "    global_step = tf.train.get_global_step()\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    train = tf.group(optimizer.minimize(loss),\n",
    "                   tf.assign_add(global_step, 1))\n",
    "    # EstimatorSpec connects subgraphs we built to the\n",
    "    # appropriate functionality.\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "      mode=mode,\n",
    "      predictions=y,\n",
    "      loss=loss,\n",
    "      train_op=train)\n",
    "\n",
    "estimator = tf.estimator.Estimator(model_fn=model_fn)\n",
    "# define our data sets\n",
    "X = np.arange(0, 1000, .2)\n",
    "#Y = np.sin(X)\n",
    "Y = X \n",
    "\n",
    "x_train, x_eval, y_train, y_eval = train_test_split(X,\\\n",
    "                                                   Y, \\\n",
    "                                                   test_size=0.25, \\\n",
    "                                                    random_state=42)\n",
    "\n",
    "bs = 100\n",
    "ep = 3000\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_train}, y_train, batch_size=bs, num_epochs=None, shuffle=True)\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_train}, y_train, batch_size=bs, num_epochs=ep, shuffle=False)\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_eval}, y_eval, batch_size=bs, num_epochs=ep, shuffle=False)\n",
    "\n",
    "# train\n",
    "estimator.train(input_fn=input_fn, steps=ep)\n",
    "# Here we evaluate how well our model did.\n",
    "train_metrics = estimator.evaluate(input_fn=train_input_fn)\n",
    "eval_metrics = estimator.evaluate(input_fn=eval_input_fn)\n",
    "print(\"train metrics: %r\"% train_metrics)\n",
    "print(\"eval metrics: %r\"% eval_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpytc1t6hb\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpytc1t6hb', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100}\n",
      "shape 5000\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmpytc1t6hb/model.ckpt.\n",
      "INFO:tensorflow:loss = 52.2943652038, step = 1\n",
      "INFO:tensorflow:global_step/sec: 325.255\n",
      "INFO:tensorflow:loss = 18.8051650889, step = 101 (0.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 309.665\n",
      "INFO:tensorflow:loss = 5.08640903713, step = 201 (0.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.134\n",
      "INFO:tensorflow:loss = 0.98918367342, step = 301 (0.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 309.783\n",
      "INFO:tensorflow:loss = 0.134541016935, step = 401 (0.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.042\n",
      "INFO:tensorflow:loss = 0.0126678687104, step = 501 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 302.191\n",
      "INFO:tensorflow:loss = 0.000819907739231, step = 601 (0.331 sec)\n",
      "INFO:tensorflow:global_step/sec: 346.382\n",
      "INFO:tensorflow:loss = 3.60467534026e-05, step = 701 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 316.406\n",
      "INFO:tensorflow:loss = 1.05631581746e-06, step = 801 (0.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.736\n",
      "INFO:tensorflow:loss = 2.00901046706e-08, step = 901 (0.328 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmpytc1t6hb/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2.50756505724e-10.\n",
      "INFO:tensorflow:Starting evaluation at 2017-09-19-05:30:14\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpytc1t6hb/model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-09-19-05:30:22\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 2.39308e-10\n",
      "INFO:tensorflow:Starting evaluation at 2017-09-19-05:30:22\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpytc1t6hb/model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-09-19-05:30:26\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 2.39302e-10\n",
      "train metrics: {'loss': 2.3930771e-10, 'global_step': 1000}\n",
      "eval metrics: {'loss': 2.3930158e-10, 'global_step': 1000}\n"
     ]
    }
   ],
   "source": [
    "#trying to get work a sin function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "\n",
    "# Declare list of features, we only have one real-valued feature\n",
    "def model_fn(features, labels, mode):\n",
    "    # Build a linear model and predict values\n",
    "    #W = tf.get_variable(\"W\", [1], dtype=tf.float64)\n",
    "    b = tf.get_variable(\"b\", [1], dtype=tf.float64)\n",
    "    #y = W * features['x'] + b\n",
    "    y = features['x'] + b\n",
    "    # Loss sub-graph\n",
    "    loss = tf.reduce_sum(tf.square(y - labels))\n",
    "    # Training sub-graph\n",
    "    global_step = tf.train.get_global_step()\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    train = tf.group(optimizer.minimize(loss),\n",
    "                   tf.assign_add(global_step, 1))\n",
    "    # EstimatorSpec connects subgraphs we built to the\n",
    "    # appropriate functionality.\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "      mode=mode,\n",
    "      predictions=y,\n",
    "      loss=loss,\n",
    "      train_op=train)\n",
    "\n",
    "estimator = tf.estimator.Estimator(model_fn=model_fn)\n",
    "# define our data sets\n",
    "X = np.arange(0, 1000, .2)\n",
    "print(\"shape \" + str(X.shape[0]))\n",
    "#Y = np.sin(X)\n",
    "Y = X \n",
    "\n",
    "x_train, x_eval, y_train, y_eval = train_test_split(X,\\\n",
    "                                                   Y, \\\n",
    "                                                   test_size=0.25, \\\n",
    "                                                    random_state=42)\n",
    "\n",
    "bs = 1000\n",
    "ep = 1000\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_train}, y_train, batch_size=bs, num_epochs=None, shuffle=True)\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_train}, y_train, batch_size=bs, num_epochs=ep, shuffle=False)\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_eval}, y_eval, batch_size=bs, num_epochs=ep, shuffle=False)\n",
    "\n",
    "# train\n",
    "estimator.train(input_fn=input_fn, steps=ep)\n",
    "# Here we evaluate how well our model did.\n",
    "train_metrics = estimator.evaluate(input_fn=train_input_fn)\n",
    "eval_metrics = estimator.evaluate(input_fn=eval_input_fn)\n",
    "print(\"train metrics: %r\"% train_metrics)\n",
    "print(\"eval metrics: %r\"% eval_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp88s60xqa\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp88s60xqa', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100}\n",
      "shape 5000\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmp88s60xqa/model.ckpt.\n",
      "INFO:tensorflow:loss = 29470.5623359, step = 1\n",
      "INFO:tensorflow:global_step/sec: 308.967\n",
      "INFO:tensorflow:loss = 28398.1637196, step = 101 (0.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.406\n",
      "INFO:tensorflow:loss = 27354.7818503, step = 201 (0.313 sec)\n",
      "INFO:tensorflow:global_step/sec: 329.584\n",
      "INFO:tensorflow:loss = 26339.9544655, step = 301 (0.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 309.194\n",
      "INFO:tensorflow:loss = 25352.9585719, step = 401 (0.323 sec)\n",
      "INFO:tensorflow:global_step/sec: 323.282\n",
      "INFO:tensorflow:loss = 24393.0996863, step = 501 (0.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 320.518\n",
      "INFO:tensorflow:loss = 23459.7105608, step = 601 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 307.217\n",
      "INFO:tensorflow:loss = 22552.1505495, step = 701 (0.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.374\n",
      "INFO:tensorflow:loss = 21669.8040614, step = 801 (0.319 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.332\n",
      "INFO:tensorflow:loss = 20812.0798076, step = 901 (0.305 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmp88s60xqa/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 19986.6295022.\n",
      "INFO:tensorflow:Starting evaluation at 2017-09-19-05:30:58\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp88s60xqa/model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-09-19-05:31:07\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 19978.7\n",
      "INFO:tensorflow:Starting evaluation at 2017-09-19-05:31:07\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp88s60xqa/model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-09-19-05:31:10\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 19978.2\n",
      "train metrics: {'loss': 19978.738, 'global_step': 1000}\n",
      "eval metrics: {'loss': 19978.16, 'global_step': 1000}\n"
     ]
    }
   ],
   "source": [
    "#trying to get work a sin function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "\n",
    "# Declare list of features, we only have one real-valued feature\n",
    "def model_fn(features, labels, mode):\n",
    "    # Build a linear model and predict values\n",
    "    #W = tf.get_variable(\"W\", [1], dtype=tf.float64)\n",
    "    b = tf.get_variable(\"b\", [1], dtype=tf.float64)\n",
    "    #y = W * features['x'] + b\n",
    "    y = features['x'] + b\n",
    "    # Loss sub-graph\n",
    "    loss = tf.reduce_sum(tf.square(y - labels))\n",
    "    # Training sub-graph\n",
    "    global_step = tf.train.get_global_step()\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    train = tf.group(optimizer.minimize(loss),\n",
    "                   tf.assign_add(global_step, 1))\n",
    "    # EstimatorSpec connects subgraphs we built to the\n",
    "    # appropriate functionality.\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "      mode=mode,\n",
    "      predictions=y,\n",
    "      loss=loss,\n",
    "      train_op=train)\n",
    "\n",
    "estimator = tf.estimator.Estimator(model_fn=model_fn)\n",
    "# define our data sets\n",
    "X = np.arange(0, 1000, .2)\n",
    "print(\"shape \" + str(X.shape[0]))\n",
    "#Y = np.sin(X)\n",
    "Y = X + 5.2\n",
    "\n",
    "x_train, x_eval, y_train, y_eval = train_test_split(X,\\\n",
    "                                                   Y, \\\n",
    "                                                   test_size=0.25, \\\n",
    "                                                    random_state=42)\n",
    "\n",
    "bs = 1000\n",
    "ep = 1000\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_train}, y_train, batch_size=bs, num_epochs=None, shuffle=True)\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_train}, y_train, batch_size=bs, num_epochs=ep, shuffle=False)\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_eval}, y_eval, batch_size=bs, num_epochs=ep, shuffle=False)\n",
    "\n",
    "# train\n",
    "estimator.train(input_fn=input_fn, steps=ep)\n",
    "# Here we evaluate how well our model did.\n",
    "train_metrics = estimator.evaluate(input_fn=train_input_fn)\n",
    "eval_metrics = estimator.evaluate(input_fn=eval_input_fn)\n",
    "print(\"train metrics: %r\"% train_metrics)\n",
    "print(\"eval metrics: %r\"% eval_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmps69xk695\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmps69xk695', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100}\n",
      "shape 5000\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmps69xk695/model.ckpt.\n",
      "INFO:tensorflow:loss = 4912.62712808, step = 1\n",
      "INFO:tensorflow:global_step/sec: 717.31\n",
      "INFO:tensorflow:loss = 4526.76583036, step = 101 (0.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 685.189\n",
      "INFO:tensorflow:loss = 4163.76934425, step = 201 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 733.497\n",
      "INFO:tensorflow:loss = 3822.85681488, step = 301 (0.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 766.695\n",
      "INFO:tensorflow:loss = 3503.05795489, step = 401 (0.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 771.426\n",
      "INFO:tensorflow:loss = 3203.44233356, step = 501 (0.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 764.026\n",
      "INFO:tensorflow:loss = 2923.11655378, step = 601 (0.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 752.83\n",
      "INFO:tensorflow:loss = 2661.2217932, step = 701 (0.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 750.223\n",
      "INFO:tensorflow:loss = 2416.93119201, step = 801 (0.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 644.095\n",
      "INFO:tensorflow:loss = 2189.44759884, step = 901 (0.155 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmps69xk695/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1980.03895213.\n",
      "INFO:tensorflow:Starting evaluation at 2017-09-19-05:32:51\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmps69xk695/model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-09-19-05:33:09\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 1978.19\n",
      "INFO:tensorflow:Starting evaluation at 2017-09-19-05:33:09\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmps69xk695/model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2017-09-19-05:33:16\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 1978.0\n",
      "train metrics: {'loss': 1978.1907, 'global_step': 1000}\n",
      "eval metrics: {'loss': 1978.0001, 'global_step': 1000}\n"
     ]
    }
   ],
   "source": [
    "#trying to get work a sin function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "\n",
    "# Declare list of features, we only have one real-valued feature\n",
    "def model_fn(features, labels, mode):\n",
    "    # Build a linear model and predict values\n",
    "    W = tf.get_variable(\"W\", [1], dtype=tf.float64)\n",
    "    b = tf.get_variable(\"b\", [1], dtype=tf.float64)\n",
    "    #y = W * features['x'] + b\n",
    "    y = features['x'] + b + W\n",
    "    # Loss sub-graph\n",
    "    loss = tf.reduce_sum(tf.square(y - labels))\n",
    "    # Training sub-graph\n",
    "    global_step = tf.train.get_global_step()\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    train = tf.group(optimizer.minimize(loss),\n",
    "                   tf.assign_add(global_step, 1))\n",
    "    # EstimatorSpec connects subgraphs we built to the\n",
    "    # appropriate functionality.\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "      mode=mode,\n",
    "      predictions=y,\n",
    "      loss=loss,\n",
    "      train_op=train)\n",
    "\n",
    "estimator = tf.estimator.Estimator(model_fn=model_fn)\n",
    "# define our data sets\n",
    "X = np.arange(0, 1000, .2)\n",
    "print(\"shape \" + str(X.shape[0]))\n",
    "#Y = np.sin(X)\n",
    "Y = X + 5.2\n",
    "\n",
    "x_train, x_eval, y_train, y_eval = train_test_split(X,\\\n",
    "                                                   Y, \\\n",
    "                                                   test_size=0.25, \\\n",
    "                                                    random_state=42)\n",
    "\n",
    "bs = 200\n",
    "ep = 1000\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_train}, y_train, batch_size=bs, num_epochs=None, shuffle=True)\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_train}, y_train, batch_size=bs, num_epochs=ep, shuffle=False)\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    {\"x\": x_eval}, y_eval, batch_size=bs, num_epochs=ep, shuffle=False)\n",
    "\n",
    "# train\n",
    "estimator.train(input_fn=input_fn, steps=ep)\n",
    "# Here we evaluate how well our model did.\n",
    "train_metrics = estimator.evaluate(input_fn=train_input_fn)\n",
    "eval_metrics = estimator.evaluate(input_fn=eval_input_fn)\n",
    "print(\"train metrics: %r\"% train_metrics)\n",
    "print(\"eval metrics: %r\"% eval_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
